{
  "hash": "24dbc38c72037670cb3d2a038a1afe88",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"MapReduce\"\n---\n\n\n\n\n\nThe **MapReduce** workflow is a programming model used for processing large data sets in parallel, typically in a distributed computing environment. It is widely used in big data processing frameworks like Hadoop and Spark. The concept revolves around two main operations:\n\n1. **Map**: Apply a function to each item in an input data set to produce a set of intermediate key-value pairs.\n2. **Reduce**: Combine all the intermediate values associated with the same key to produce the final result.\n\n## MapReduce Workflow in Python\n\nIn Python, you can implement a MapReduce-style workflow using built-in functions like `map()` and `reduce()` (from the `functools` module). While the traditional MapReduce model is meant for distributed systems, the same concept can be used in Python for processing data in a more manageable and parallelizable manner.\n\n### Explanation of Map and Reduce:\n1. **Map**:\n   \n   - The `map()` function applies a given function to each item in an input iterable (e.g., list, tuple) and returns an iterator with the results.\n   - This is equivalent to the \"mapping\" operation in the MapReduce model, where you transform input data into intermediate data.\n\n2. **Reduce**:\n   \n   - The `reduce()` function from the `functools` module accumulates a result by applying a binary function (a function that takes two arguments) to elements of an iterable, combining them into a single output value.\n   - This is equivalent to the \"reducing\" operation in the MapReduce model, where you aggregate or combine intermediate results to produce the final output.\n\n\n### Example: Word Count using MapReduce in Python\n\nA classic example of MapReduce is the **Word Count** problem, where you want to count the frequency of each word in a list of sentences.\n\n::: {#548aeefd .cell execution_count=1}\n``` {.python .cell-code}\nfrom functools import reduce\n\n# Sample data: List of sentences\ndata = [\n    \"hello world\",\n    \"hello\",\n    \"hello map reduce\",\n    \"map reduce example\"\n]\n```\n:::\n\n\n#### Step 1: Map\n\n- Create a list of (word, 1) pairs\n\n::: {#62a5bc70 .cell execution_count=2}\n``` {.python .cell-code}\ndef map_words(sentence):\n    words = sentence.split()\n    return [(word, 1) for word in words]\n\n# Applying the map function to all sentences and converting the map object to a list\nmapped = list(map(map_words, data))\nmapped\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n[[('hello', 1), ('world', 1)],\n [('hello', 1)],\n [('hello', 1), ('map', 1), ('reduce', 1)],\n [('map', 1), ('reduce', 1), ('example', 1)]]\n```\n:::\n:::\n\n\n::: {#39bdd33e .cell execution_count=3}\n``` {.python .cell-code}\n# Flatten the list of lists into a single list of (word, 1) pairs\nflattened = [pair for sublist in mapped for pair in sublist]\nflattened\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n[('hello', 1),\n ('world', 1),\n ('hello', 1),\n ('hello', 1),\n ('map', 1),\n ('reduce', 1),\n ('map', 1),\n ('reduce', 1),\n ('example', 1)]\n```\n:::\n:::\n\n\n#### Step 2: Reduce phase\n\n- Sum up the values for each unique word\n\n::: {#6cf65de9 .cell execution_count=4}\n``` {.python .cell-code}\n# First, group by words using a dictionary\nword_count_dict = {}\nfor word, count in flattened:\n    if word in word_count_dict:\n        word_count_dict[word] += count\n    else:\n        word_count_dict[word] = count\n\nword_count_dict\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n{'hello': 3, 'world': 1, 'map': 2, 'reduce': 2, 'example': 1}\n```\n:::\n:::\n\n\nOr\n\n::: {#93d5925c .cell execution_count=5}\n``` {.python .cell-code}\ndef reduce_word_counts(acc, pair):\n    word, count = pair\n    if word in acc:\n        acc[word] += count\n    else:\n        acc[word] = count\n    return acc\n\nword_count_dict = reduce(reduce_word_counts, flattened, {})\nword_count_dict\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n{'hello': 3, 'world': 1, 'map': 2, 'reduce': 2, 'example': 1}\n```\n:::\n:::\n\n\n#### Explanation:\n\n1. **Map Phase**:\n   \n   - The function `map_words(sentence)` takes a sentence, splits it into words, and returns a list of `(word, 1)` pairs.\n   - `map(map_words, data)` applies this function to each sentence in `data`, resulting in a list of lists of `(word, 1)` pairs.\n\n2. **Flattening**:\n\n   - The nested list produced by `map()` is flattened into a single list of `(word, 1)` pairs using a list comprehension: `[pair for sublist in mapped for pair in sublist]`.\n\n3. **Reduce Phase**:\n\n   - The word count is accumulated in a dictionary, `word_count_dict`. For each `(word, 1)` pair, the count for that word is increased in the dictionary.\n   - Alternatively, you can use the `reduce()` function to perform this operation, as shown in the commented-out section.\n\n\n\n#### Summary\n\n- **Map**: Transforms the data into key-value pairs.\n- **Reduce**: Aggregates or combines the key-value pairs to produce the final result.\n\n#### Why Use MapReduce?\n\n- It is ideal for parallel processing large datasets by breaking down the work into smaller, manageable chunks.\n\n- The `map()` and `reduce()` functions in Python allow you to mimic this process on smaller data sets or locally, without needing a distributed environment.\n\nWhile this example uses a simple in-memory approach, the MapReduce framework is typically used in distributed computing for large-scale data processing tasks.\n\n",
    "supporting": [
      "map-reduce_files"
    ],
    "filters": [],
    "includes": {}
  }
}